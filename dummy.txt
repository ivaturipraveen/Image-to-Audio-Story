from transformers import pipeline
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.llms import OpenAI
from PIL import Image
import streamlit as st
from gtts import gTTS
import os
from dotenv import find_dotenv, load_dotenv
import openai

# Load environment variables
load_dotenv(find_dotenv())

# Define the Hugging Face Hub API Token and OpenAI API Key
HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# Set the OpenAI API key
openai.api_key = OPENAI_API_KEY

# Function to extract text from an image using Hugging Face model
def img2text(image_path):
    image_to_text = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")
    text = image_to_text(image_path)[0]['generated_text']
    print(text)
    return text

# Function to generate a story based on a scenario using OpenAI's GPT-3.5-turbo
def generate_story(scenario):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": "You possess a remarkable talent for storytelling; weaving narratives that captivate and resonate. Let's craft a compelling short story with 3 small paragraphs."
            },
            {
                "role": "user",
                "content": f"CONTEXT: {scenario}\nSTORY:"
            }
        ]
    )

    story = response['choices'][0]['message']['content']
    print(story)
    return story

# Streamlit application
def main():
    st.set_page_config(
        page_title="Image to Audio Story",
        page_icon="üì∏üîä"
    )

    st.markdown("<h1 style='text-align: center; margin-top: -30px;'>Transform Images to Audio Stories üñºÔ∏è‚û°Ô∏èüîä</h1>", unsafe_allow_html=True)

    st.sidebar.title("üé® Upload Your Image!")
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type="jpg")

    if uploaded_file is not None:
        bytes_data = uploaded_file.getvalue()
        with open(uploaded_file.name, "wb") as file:
            file.write(bytes_data)
        st.sidebar.image(uploaded_file, caption='Uploaded Image.', use_column_width=True)
        scenario = img2text(uploaded_file.name)
        story = generate_story(scenario)

        with st.expander("Scenario"):
            st.write(scenario)

        with st.expander("Story"):
            st.write(story)

        tts = gTTS(text=story, lang='en')
        tts.save('audio.mp3')
        audio_file = open('audio.mp3', 'rb')
        audio_bytes = audio_file.read()

        st.audio(audio_bytes, format="audio/mp3")

if __name__ == '__main__':
    main()


#Summary of New Features
#Image Enhancement: Improves the image quality before generating a caption.
#Language Translation: Allows translating the generated story into different languages.
#Interactive UI for Parameter Tuning: Users can adjust text generation parameters and background music volume using Streamlit sliders
#HUGGINGFACEHUB_API_TOKEN
# streamlit run app.py
#OPENAI_API_KEY
#streamlit run app.py

